{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1sQomNU20soVULTIJHhF7fSH451W9YGui",
      "authorship_tag": "ABX9TyMvf/iDTOXJG2/9hB5GAjUy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hirokiyamauch/NLP_100knock/blob/%E7%AC%AC9%E7%AB%A0/80_89.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3J08qthCtGO",
        "outputId": "4fbe5ef2-ff76-43e3-ca88-c446f8220515"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-24 16:18:23--  https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29224203 (28M) [application/x-httpd-php]\n",
            "Saving to: ‘NewsAggregatorDataset.zip’\n",
            "\n",
            "NewsAggregatorDatas 100%[===================>]  27.87M  21.3MB/s    in 1.3s    \n",
            "\n",
            "2022-08-24 16:18:25 (21.3 MB/s) - ‘NewsAggregatorDataset.zip’ saved [29224203/29224203]\n",
            "\n",
            "Archive:  NewsAggregatorDataset.zip\n",
            "  inflating: 2pageSessions.csv       \n",
            "   creating: __MACOSX/\n",
            "  inflating: __MACOSX/._2pageSessions.csv  \n",
            "  inflating: newsCorpora.csv         \n",
            "  inflating: __MACOSX/._newsCorpora.csv  \n",
            "  inflating: readme.txt              \n",
            "  inflating: __MACOSX/._readme.txt   \n"
          ]
        }
      ],
      "source": [
        "# データのダウンロード\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip\n",
        "!unzip NewsAggregatorDataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -e 's/\"/'\\''/g' ./newsCorpora.csv > ./newsCorpora_re.csv"
      ],
      "metadata": {
        "id": "ZIhC5lMH3SWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"/content/newsCorpora_re.csv\", header=None, sep=\"\\t\", names=[\"ID\" ,\"TITLE\" ,\"URL\" ,\"PUBLISHER\" ,\"CATEGORY\" ,\"STORY\" ,\"HOSTNAME\" ,\"TIMESTAMP\"])\n",
        "\n",
        "print(data)"
      ],
      "metadata": {
        "id": "Zyy0WuXOC2pF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10dc40f1-f278-40b2-c894-9f7b1079b6ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            ID                                              TITLE  \\\n",
            "0            1  Fed official says weak data caused by weather,...   \n",
            "1            2  Fed's Charles Plosser sees high bar for change...   \n",
            "2            3  US open: Stocks fall after Fed official hints ...   \n",
            "3            4  Fed risks falling 'behind the curve', Charles ...   \n",
            "4            5  Fed's Plosser: Nasty Weather Has Curbed Job Gr...   \n",
            "...        ...                                                ...   \n",
            "422932  422933  Surgeons to remove 4-year-old's rib to rebuild...   \n",
            "422933  422934  Boy to have surgery on esophagus after battery...   \n",
            "422934  422935  Child who swallowed battery to have reconstruc...   \n",
            "422935  422936  Phoenix boy undergoes surgery to repair throat...   \n",
            "422936  422937  Phoenix boy undergoes surgery to repair throat...   \n",
            "\n",
            "                                                      URL          PUBLISHER  \\\n",
            "0       http://www.latimes.com/business/money/la-fi-mo...  Los Angeles Times   \n",
            "1       http://www.livemint.com/Politics/H2EvwJSK2VE6O...           Livemint   \n",
            "2       http://www.ifamagazine.com/news/us-open-stocks...       IFA Magazine   \n",
            "3       http://www.ifamagazine.com/news/fed-risks-fall...       IFA Magazine   \n",
            "4       http://www.moneynews.com/Economy/federal-reser...          Moneynews   \n",
            "...                                                   ...                ...   \n",
            "422932  http://www.cbs3springfield.com/story/26378648/...            WSHM-TV   \n",
            "422933  http://www.wlwt.com/news/boy-to-have-surgery-o...    WLWT Cincinnati   \n",
            "422934  http://www.newsnet5.com/news/local-news/child-...       NewsNet5.com   \n",
            "422935  http://www.wfsb.com/story/26368078/phoenix-boy...               WFSB   \n",
            "422936  http://www.cbs3springfield.com/story/26368078/...            WSHM-TV   \n",
            "\n",
            "       CATEGORY                          STORY                 HOSTNAME  \\\n",
            "0             b  ddUyU0VZz0BRneMioxUPQVP6sIxvM          www.latimes.com   \n",
            "1             b  ddUyU0VZz0BRneMioxUPQVP6sIxvM         www.livemint.com   \n",
            "2             b  ddUyU0VZz0BRneMioxUPQVP6sIxvM      www.ifamagazine.com   \n",
            "3             b  ddUyU0VZz0BRneMioxUPQVP6sIxvM      www.ifamagazine.com   \n",
            "4             b  ddUyU0VZz0BRneMioxUPQVP6sIxvM        www.moneynews.com   \n",
            "...         ...                            ...                      ...   \n",
            "422932        m  dpcLMoJD69UYMXMxaoEFnWql9YjQM  www.cbs3springfield.com   \n",
            "422933        m  dpcLMoJD69UYMXMxaoEFnWql9YjQM             www.wlwt.com   \n",
            "422934        m  dpcLMoJD69UYMXMxaoEFnWql9YjQM         www.newsnet5.com   \n",
            "422935        m  dpcLMoJD69UYMXMxaoEFnWql9YjQM             www.wfsb.com   \n",
            "422936        m  dpcLMoJD69UYMXMxaoEFnWql9YjQM  www.cbs3springfield.com   \n",
            "\n",
            "            TIMESTAMP  \n",
            "0       1394470370698  \n",
            "1       1394470371207  \n",
            "2       1394470371550  \n",
            "3       1394470371793  \n",
            "4       1394470372027  \n",
            "...               ...  \n",
            "422932  1409229190251  \n",
            "422933  1409229190508  \n",
            "422934  1409229190771  \n",
            "422935  1409229191071  \n",
            "422936  1409229191565  \n",
            "\n",
            "[422937 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "file_df = data.loc[data['PUBLISHER'].isin(['Reuters', 'Huffington Post', 'Businessweek', 'Contactmusic.com', 'Daily Mail']), ['TITLE', 'CATEGORY']]\n",
        "\n",
        "train_data, teva_data = train_test_split(file_df, shuffle=True, test_size=0.2, random_state=42, stratify= file_df['CATEGORY'])\n",
        "valid_data, test_data = train_test_split(teva_data, shuffle=True, test_size=0.5, random_state=42, stratify= teva_data['CATEGORY'])\n",
        "train_data.to_csv(\"train.txt\", sep=\"\\t\")\n",
        "valid_data.to_csv(\"valid.txt\", sep=\"\\t\")\n",
        "test_data.to_csv(\"test.txt\", sep=\"\\t\")"
      ],
      "metadata": {
        "id": "xpcC_120C4Es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 事例数の確認\n",
        "print('【学習データ】')\n",
        "print(train_data['CATEGORY'].value_counts())\n",
        "print('【検証データ】')\n",
        "print(valid_data['CATEGORY'].value_counts())\n",
        "print('【評価データ】')\n",
        "print(test_data['CATEGORY'].value_counts())"
      ],
      "metadata": {
        "id": "tI3vvZGw59Lq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "814d10b9-131c-4b0f-dc77-7cb2ec963c11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "【学習データ】\n",
            "b    4501\n",
            "e    4235\n",
            "t    1220\n",
            "m     728\n",
            "Name: CATEGORY, dtype: int64\n",
            "【検証データ】\n",
            "b    563\n",
            "e    529\n",
            "t    153\n",
            "m     91\n",
            "Name: CATEGORY, dtype: int64\n",
            "【評価データ】\n",
            "b    563\n",
            "e    530\n",
            "t    152\n",
            "m     91\n",
            "Name: CATEGORY, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def word_counter(file):\n",
        "  counter_dic = {}\n",
        "  for lines in file:\n",
        "    sentence = lines.split()\n",
        "    for word in sentence:\n",
        "        #出現しない言語は新しく保存\n",
        "        if not word in counter_dic:\n",
        "            counter_dic[word] = 1\n",
        "        #出現する場合はcounterを増やす\n",
        "        else:\n",
        "           cnt = counter_dic[word]\n",
        "           cnt += 1\n",
        "           counter_dic[word] = cnt\n",
        "\n",
        "  count_list = sorted(counter_dic.items(), reverse=True, key=lambda x : x[1])\n",
        "  counter_dic.clear()\n",
        "  counter_dic.update(count_list)\n",
        "\n",
        "  id_word_dic = make_count_ID(count_list)\n",
        "\n",
        "  return id_word_dic\n",
        "\n",
        "#頻出単語順にIDをわりふり\n",
        "def make_count_ID(count_list):\n",
        "    id_word_dic = {}\n",
        "    for i, li in enumerate(count_list):\n",
        "        if li[1] >= 2:\n",
        "            id_word_dic[li[0]] = (i+1)\n",
        "    \n",
        "    return id_word_dic\n",
        "\n",
        "df_title = train_data[\"TITLE\"]\n",
        "id_word_dic = word_counter(df_title) "
      ],
      "metadata": {
        "id": "pTdryrAYD7Lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def id_transform(lines, id_word_dic=id_word_dic):\n",
        "  id_transform_file = []\n",
        "  sentence = lines.split()\n",
        "  ids = []\n",
        "  #一単語ごとにdicで出現頻度が2回以上の場合、IDを付与\n",
        "  for word in sentence:\n",
        "        if word in id_word_dic:\n",
        "            ids.append(int(id_word_dic[word]))\n",
        "        else:\n",
        "            ids.append(0)\n",
        "  id_transform_file = ids\n",
        "  \n",
        "  return id_transform_file"
      ],
      "metadata": {
        "id": "eEmCIfebFOTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "81"
      ],
      "metadata": {
        "id": "7XEXJHEGuMo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CreateDataset(Dataset):\n",
        "  def __init__(self, X, y, tokenizer):\n",
        "    self.data = X\n",
        "    self.label = y\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  def __len__(self):  # len(Dataset)で返す値を指定\n",
        "    return len(self.label)\n",
        "\n",
        "  def __getitem__(self, index):  # Dataset[index]で返す値を指定\n",
        "    text = self.data[index]\n",
        "    label_puts = self.label[index]\n",
        "\n",
        "    if self.tokenizer:\n",
        "        inputs = self.tokenizer(text)\n",
        "        \n",
        "    return torch.tensor(inputs, dtype=torch.int64), torch.tensor(label_puts, dtype=torch.int64)"
      ],
      "metadata": {
        "id": "JZ1mGRlne8dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyRNN(torch.nn.Module):\n",
        "    # 埋め込み層, 隠れ層, 全結合層の定義 \n",
        "    def __init__(self, vocab_size, input_size,padding_idx, output_size, hidden_size, device):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.hidden_size = hidden_size\n",
        "        self.emb = nn.Embedding(vocab_size, input_size, padding_idx=padding_idx)\n",
        "        self.rnn = torch.nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    # 順伝播\n",
        "    def forward(self, x):\n",
        "        self.batch_size = x.size()[0]\n",
        "        hidden = self.init_hidden() \n",
        "        output, h = self.rnn(self.emb(x), hidden)\n",
        "        output = self.fc(output[:, -1, :])\n",
        "        return output\n",
        "\n",
        "    def init_hidden(self):\n",
        "        hidden = torch.zeros(1, self.batch_size, self.hidden_size).to(self.device)\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "J1J955-RuN4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['TITLE'].values.tolist()[0]"
      ],
      "metadata": {
        "id": "hD1ovy_W1heD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d0e990ca-7a51-4f45-fcac-94b590db88bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'UPDATE 1-Sandwich chain Quiznos files for bankruptcy protection'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "# ラベルベクトルの作成\n",
        "category_dict = {'b': 0, 't': 1, 'e':2, 'm':3}\n",
        "y_train = train_data[\"CATEGORY\"].map(lambda x: category_dict[x]).values\n",
        "y_valid = valid_data[\"CATEGORY\"].map(lambda x: category_dict[x]).values\n",
        "y_test = test_data[\"CATEGORY\"].map(lambda x: category_dict[x]).values\n"
      ],
      "metadata": {
        "id": "-hp2wvDG1tt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Datasetの作成\n",
        "dataset_train = CreateDataset(train_data[\"TITLE\"].values.tolist(), y_train, id_transform)\n",
        "dataset_valid = CreateDataset(valid_data[\"TITLE\"].values.tolist(), y_valid, id_transform)\n",
        "dataset_test = CreateDataset(test_data[\"TITLE\"].values.tolist(), y_test, id_transform)\n",
        "print('Dataset[index]の出力:')\n",
        "print(dataset_train[0])"
      ],
      "metadata": {
        "id": "6-SZLsk_j_Jv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8acef0f-7641-4893-94bd-9fa481ff3ca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset[index]の出力:\n",
            "(tensor([   5,    0, 1657,    0,  669,    9, 1272, 3277]), tensor(0))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# パラメータの設定\n",
        "VOCAB_SIZE = len(set(id_word_dic.values())) + 1  # 辞書のID数 + パディングID\n",
        "EMB_SIZE = 300\n",
        "PADDING_IDX = len(set(id_word_dic.values()))\n",
        "OUTPUT_SIZE = 4\n",
        "HIDDEN_SIZE = 50\n",
        "device = torch.device(\"cpu\")\n",
        "# モデルの定義\n",
        "model = MyRNN(VOCAB_SIZE, EMB_SIZE, PADDING_IDX, OUTPUT_SIZE, HIDDEN_SIZE,device)\n",
        "\n",
        "for i in range(10):\n",
        "  X = dataset_train[i][0]\n",
        "  print(torch.softmax(model(X.unsqueeze(0)), dim=-1))"
      ],
      "metadata": {
        "id": "-DXGcf3IpiXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6b3d417-2fdf-4c99-8d00-6413f6d02d72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1862, 0.2059, 0.3159, 0.2921]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2380, 0.2404, 0.3621, 0.1596]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2353, 0.3172, 0.0700, 0.3775]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3127, 0.1111, 0.4381, 0.1382]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2081, 0.3013, 0.1488, 0.3418]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.4683, 0.1495, 0.1630, 0.2191]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3597, 0.1627, 0.2883, 0.1893]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.3670, 0.1257, 0.1317, 0.3756]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1501, 0.4690, 0.1844, 0.1966]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2003, 0.3011, 0.1837, 0.3149]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "82"
      ],
      "metadata": {
        "id": "IDwWJ_Nv4UoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 1\n",
        "\n",
        "#データセットからデータローダを作成\n",
        "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(dataset_valid, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "RPxe0o8x4V6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "def calculate_loss_and_accuracy(model, criterion, dataloader, device):\n",
        "  \"\"\"損失・正解率を計算\"\"\"\n",
        "  loss = 0\n",
        "  with torch.no_grad():\n",
        "      acc_list = []\n",
        "      for batch in dataloader:\n",
        "        x, t = batch\n",
        "        # デバイスの指定\n",
        "        x = x.to(device)\n",
        "        t = t.to(device)\n",
        "\n",
        "        # 順伝播\n",
        "        outputs = model(x)\n",
        "\n",
        "        # 損失計算\n",
        "        loss += criterion(outputs, t).item()\n",
        "\n",
        "        # 正解率計算\n",
        "        pred = torch.argmax(outputs, dim=-1)\n",
        "        acc = accuracy_score(pred, t)\n",
        "        acc_list.append(acc)\n",
        "\n",
        "  return loss / len(dataloader), torch.tensor(acc_list).mean()"
      ],
      "metadata": {
        "id": "63cCOVha4kUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# パラメータの設定\n",
        "VOCAB_SIZE = len(set(id_word_dic.values())) + 1  # 辞書のID数 + パディングID\n",
        "EMB_SIZE = 300\n",
        "PADDING_IDX = len(set(id_word_dic.values()))\n",
        "OUTPUT_SIZE = 4\n",
        "HIDDEN_SIZE = 50\n",
        "\n",
        "\n",
        "# モデルの定義\n",
        "model = MyRNN(VOCAB_SIZE, EMB_SIZE, PADDING_IDX, OUTPUT_SIZE, HIDDEN_SIZE, device)\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "max_epoch=10\n",
        "train_loss_log, train_acc_log = [], [] \n",
        "valid_loss_log, valid_acc_log = [], [] \n",
        "for epoch in range(max_epoch):\n",
        "    for batch in train_loader:\n",
        "        x, t = batch  # バッチサイズ分のサンプルを抽出\n",
        "        optimizer.zero_grad()   # 勾配を初期化\n",
        "\n",
        "        # 順伝播\n",
        "        y = model(x) \n",
        "        loss = criterion(y, t)\n",
        "        # 誤差逆伝播\n",
        "        loss.backward()\n",
        "        optimizer.step() \n",
        "\n",
        "    # 学習データの損失、正解率を確認\n",
        "    train_loss, train_acc = calculate_loss_and_accuracy(model, criterion, train_loader, device)\n",
        "    # 検証データの損失、正解率を確認\n",
        "    valid_loss, valid_acc = calculate_loss_and_accuracy(model, criterion, valid_loader, device)\n",
        "    print(\"epoch: %d    train_loss: %.3f   train_acc: %.3f   valid_loss: %.3f   valid_acc: %.3f\" % (epoch+1, train_loss, train_acc, valid_loss, valid_acc))\n",
        "\n",
        "    # 進捗状況の保存\n",
        "    train_loss_log.append(train_loss)\n",
        "    train_acc_log.append(train_acc)\n",
        "    valid_loss_log.append(valid_loss)\n",
        "    valid_acc_log.append(valid_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "JCqML9kl47CM",
        "outputId": "3d0b0667-4762-4d8c-bbc4-f8155cb3604a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-ae420fc8dba8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# 誤差逆伝播\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# 学習データの損失、正解率を確認\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mhas_sparse_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_sparse_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                 foreach=group['foreach'])\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;31m# update momentum_buffers in state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[1;32m    204\u001b[0m          \u001b[0mnesterov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnesterov\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m          \u001b[0mhas_sparse_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_sparse_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m          maximize=maximize)\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m def _single_tensor_sgd(params: List[Tensor],\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36m_single_tensor_sgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmaximize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def visualize_logs():\n",
        "  fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
        "  ax[0].plot(train_loss_log, label='train')\n",
        "  ax[0].plot(valid_loss_log, label='valid')\n",
        "  ax[0].set_xlabel('epoch')\n",
        "  ax[0].set_ylabel('loss')\n",
        "  ax[0].legend()\n",
        "  ax[1].plot(train_acc_log, label='train')\n",
        "  ax[1].plot(valid_acc_log, label='valid')\n",
        "  ax[1].set_xlabel('epoch')\n",
        "  ax[1].set_ylabel('accuracy')\n",
        "  ax[1].legend()\n",
        "  plt.show()\n",
        "visualize_logs()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "v9AIcyhADgHL",
        "outputId": "c9dd8ebe-02c5-406e-93f3-563c4e8ed2d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "83"
      ],
      "metadata": {
        "id": "6hOqovdzT7iE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr-lhMGiG3ez",
        "outputId": "fdc68c65-463f-4e4c-d9e6-5caaae6abdac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def padsequence(batch):\n",
        "  #Dataloaderからミニバッチを取り出すごとに最大系列長でパディング\n",
        "    sorted_batch = sorted(batch, key=lambda x: x[0].shape[0], reverse=True)\n",
        "    sequences = [x[0] for x in sorted_batch]\n",
        "    sequences_padded = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True, padding_value=PADDING_IDX)\n",
        "    labels = torch.LongTensor([x[1] for x in sorted_batch])\n",
        "\n",
        "    return sequences_padded,labels"
      ],
      "metadata": {
        "id": "vT8b-OI3ITLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss_and_accuracy(model, criterion, dataloader, device):\n",
        "  \"\"\"損失・正解率を計算\"\"\"\n",
        "  loss = 0\n",
        "  with torch.no_grad():\n",
        "      acc_list = []\n",
        "      for batch in dataloader:\n",
        "        x, t = batch\n",
        "        # デバイスの指定\n",
        "        x = x.to(device)\n",
        "        t = t.to(device)\n",
        "\n",
        "        # 順伝播\n",
        "        outputs = model(x)\n",
        "\n",
        "        # 損失計算\n",
        "        loss += criterion(outputs, t).item()\n",
        "\n",
        "        # 正解率計算\n",
        "        pred = torch.argmax(outputs, dim=-1)\n",
        "        acc = (pred == t).sum() * 1.0 / len(t)\n",
        "        acc_list.append(acc)\n",
        "\n",
        "  return loss / len(dataloader), torch.tensor(acc_list).mean()"
      ],
      "metadata": {
        "id": "bLiDZzCKLtxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# パラメータの設定\n",
        "VOCAB_SIZE = len(set(id_word_dic.values())) + 1  # 辞書のID数 + パディングID\n",
        "EMB_SIZE = 300\n",
        "PADDING_IDX = len(set(id_word_dic.values()))\n",
        "OUTPUT_SIZE = 4\n",
        "HIDDEN_SIZE = 50\n",
        "\n",
        "\n",
        "# モデルの定義\n",
        "model = MyRNN(VOCAB_SIZE, EMB_SIZE, PADDING_IDX, OUTPUT_SIZE, HIDDEN_SIZE, device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "max_epoch=1\n",
        "train_loss_log, train_acc_log = [], [] \n",
        "valid_loss_log, valid_acc_log = [], [] \n",
        "\n",
        "for batch_size in [2,4,6,8,10]:\n",
        "    train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, collate_fn=padsequence)\n",
        "    valid_loader = DataLoader(dataset_valid, batch_size=batch_size, shuffle=False, collate_fn=padsequence)\n",
        "    for epoch in range(max_epoch):\n",
        "        for batch in train_loader:\n",
        "            x, t = batch  # バッチサイズ分のサンプルを抽出\n",
        "            x = x.to(device)\n",
        "            t = t.to(device)\n",
        "\n",
        "            optimizer.zero_grad()   # 勾配を初期化\n",
        "            # 順伝播\n",
        "            y = model(x) \n",
        "            loss = criterion(y, t)\n",
        "            # 誤差逆伝播\n",
        "            loss.backward()\n",
        "            optimizer.step() \n",
        "\n",
        "        # 学習データの損失、正解率を確認\n",
        "        train_loss, train_acc = calculate_loss_and_accuracy(model, criterion, train_loader, device)\n",
        "        # 検証データの損失、正解率を確認\n",
        "        valid_loss, valid_acc = calculate_loss_and_accuracy(model, criterion, valid_loader, device)\n",
        "        print(\"batch_size: %d   epoch: %d    train_loss: %.3f   train_acc: %.3f   valid_loss: %.3f   valid_acc: %.3f\" % (batch_size, epoch+1, train_loss, train_acc, valid_loss, valid_acc))\n",
        "\n",
        "        # 進捗状況の保存\n",
        "        train_loss_log.append(train_loss)\n",
        "        train_acc_log.append(train_acc)\n",
        "        valid_loss_log.append(valid_loss)\n",
        "        valid_acc_log.append(valid_acc)"
      ],
      "metadata": {
        "id": "ETO8eIedIhlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "84"
      ],
      "metadata": {
        "id": "vGh9_xBET-0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install gensim==4.0.1\n",
        "\n",
        "import gensim\n",
        "gensim.__version__"
      ],
      "metadata": {
        "id": "ZV9bfdfzR8Z6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "103ef11a-15ce-4153-892d-4892845b78ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gensim==4.0.1\n",
            "  Downloading gensim-4.0.1-cp37-cp37m-manylinux1_x86_64.whl (23.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.9 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.0.1) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.0.1) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim==4.0.1) (1.21.6)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4.0.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習済み単語ベクトルのダウンロード\n",
        "FILE_ID = \"0B7XkCwpI5KDYNlNUTTlSS21pQmM\"\n",
        "FILE_NAME = \"GoogleNews-vectors-negative300.bin.gz\"\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=$FILE_ID' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=$FILE_ID\" -O $FILE_NAME && rm -rf /tmp/cookies.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZ_V8bPCVyir",
        "outputId": "25751453-aeb3-4237-f9a8-c0e86be9a9b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-24 16:20:05--  https://docs.google.com/uc?export=download&confirm=&id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
            "Resolving docs.google.com (docs.google.com)... 142.251.107.113, 142.251.107.139, 142.251.107.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.251.107.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors-     [ <=>                ]   2.33K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-08-24 16:20:05 (23.1 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [2386]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "vector = KeyedVectors.load_word2vec_format(\"/content/drive/MyDrive/GoogleNews-vectors-negative300.bin.gz\", binary=True)"
      ],
      "metadata": {
        "id": "adP0IzJqWHVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 学習済み単語ベクトルの取得\n",
        "VOCAB_SIZE = len(set(id_word_dic.values())) + 1\n",
        "EMB_SIZE = 300\n",
        "weights = np.zeros((VOCAB_SIZE, EMB_SIZE))\n",
        "words_in_pretrained = 0\n",
        "for i, word in enumerate(id_word_dic.keys()):\n",
        "  try:\n",
        "    weights[i] = vector[word]\n",
        "    words_in_pretrained += 1\n",
        "  except KeyError:\n",
        "    weights[i] = np.random.normal(scale=0.4, size=(EMB_SIZE,))\n",
        "weights = torch.from_numpy(weights.astype((np.float32)))\n",
        "\n",
        "print(f'学習済みベクトル利用単語数: {words_in_pretrained} / {VOCAB_SIZE}')\n",
        "print(weights.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN7nEJ-LXeDG",
        "outputId": "618b28c2-6958-4b73-f1de-2966cca9cc36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "学習済みベクトル利用単語数: 8295 / 10306\n",
            "torch.Size([10306, 300])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyRNN(nn.Module):\n",
        "  def __init__(self, vocab_size, emb_size, hidden_size, num_layers, output_size, padding_idx, bidirectional, device, emb_weights=None):\n",
        "    super().__init__()\n",
        "    self.device = device\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.num_directions = bidirectional + 1  # 単方向：1、双方向：2\n",
        "    if emb_weights != None:  # 指定があれば埋め込み層の重みをemb_weightsで初期化\n",
        "      self.emb = nn.Embedding.from_pretrained(emb_weights, padding_idx=padding_idx)\n",
        "    else:\n",
        "      self.emb = nn.Embedding(vocab_size, emb_size, padding_idx=padding_idx)\n",
        "    self.rnn = nn.RNN(emb_size, hidden_size, num_layers, bidirectional=bidirectional, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_size * self.num_directions, output_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "        self.batch_size = x.size()[0]\n",
        "        hidden = self.init_hidden() \n",
        "        output, h = self.rnn(self.emb(x), hidden)\n",
        "        output = self.fc(output[:, -1, :])\n",
        "        return output\n",
        "\n",
        "  def init_hidden(self):\n",
        "    hidden = torch.zeros(self.num_layers * self.num_directions, self.batch_size, self.hidden_size).to(self.device)\n",
        "    return hidden"
      ],
      "metadata": {
        "id": "Gp8rRprYY7un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# パラメータの設定\n",
        "VOCAB_SIZE = len(set(id_word_dic.values())) + 1  # 辞書のID数 + パディングID\n",
        "EMB_SIZE = 300\n",
        "PADDING_IDX = len(set(id_word_dic.values()))\n",
        "num_layers=1\n",
        "OUTPUT_SIZE = 4\n",
        "HIDDEN_SIZE = 50\n",
        "bidirectional = False\n",
        "print(device)\n",
        "\n",
        "# モデルの定義\n",
        "model = MyRNN(VOCAB_SIZE, EMB_SIZE, HIDDEN_SIZE, num_layers, OUTPUT_SIZE, PADDING_IDX, bidirectional, device, emb_weights=weights)\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "max_epoch=1\n",
        "train_loss_log, train_acc_log = [], [] \n",
        "valid_loss_log, valid_acc_log = [], [] \n",
        "for epoch in range(max_epoch):\n",
        "    for batch in train_loader:\n",
        "        x, t = batch  # バッチサイズ分のサンプルを抽出\n",
        "        optimizer.zero_grad()   # 勾配を初期化\n",
        "\n",
        "        # 順伝播\n",
        "        y = model(x) \n",
        "        loss = criterion(y, t)\n",
        "        # 誤差逆伝播\n",
        "        loss.backward()\n",
        "        optimizer.step() \n",
        "\n",
        "    # 学習データの損失、正解率を確認\n",
        "    train_loss, train_acc = calculate_loss_and_accuracy(model, criterion, train_loader, device)\n",
        "    # 検証データの損失、正解率を確認\n",
        "    valid_loss, valid_acc = calculate_loss_and_accuracy(model, criterion, valid_loader, device)\n",
        "    print(\"epoch: %d    train_loss: %.3f   train_acc: %.3f   valid_loss: %.3f   valid_acc: %.3f\" % (epoch+1, train_loss, train_acc, valid_loss, valid_acc))\n",
        "\n",
        "    # 進捗状況の保存\n",
        "    train_loss_log.append(train_loss)\n",
        "    train_acc_log.append(train_acc)\n",
        "    valid_loss_log.append(valid_loss)\n",
        "    valid_acc_log.append(valid_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNZpFzVaZMds",
        "outputId": "30f6a1ec-1c23-4a20-a729-740fc078c084"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "epoch: 1    train_loss: 0.979   train_acc: 0.643   valid_loss: 1.009   valid_acc: 0.635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def visualize_logs():\n",
        "  fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
        "  ax[0].plot(train_loss_log, label='train')\n",
        "  ax[0].plot(valid_loss_log, label='valid')\n",
        "  ax[0].set_xlabel('epoch')\n",
        "  ax[0].set_ylabel('loss')\n",
        "  ax[0].legend()\n",
        "  ax[1].plot(train_acc_log, label='train')\n",
        "  ax[1].plot(valid_acc_log, label='valid')\n",
        "  ax[1].set_xlabel('epoch')\n",
        "  ax[1].set_ylabel('accuracy')\n",
        "  ax[1].legend()\n",
        "  plt.show()\n",
        "visualize_logs()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "bH0ffWhlkf6q",
        "outputId": "6b5c3e31-d855-4f94-be70-c32a12aa623d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "85. 双方向RNN・多層化"
      ],
      "metadata": {
        "id": "kSJYca7hikR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# パラメータの設定\n",
        "VOCAB_SIZE = len(set(id_word_dic.values())) + 1  # 辞書のID数 + パディングID\n",
        "EMB_SIZE = 300\n",
        "PADDING_IDX = len(set(id_word_dic.values()))\n",
        "num_layers=1\n",
        "OUTPUT_SIZE = 4\n",
        "HIDDEN_SIZE = 50\n",
        "bidirectional = True\n",
        "print(device)\n",
        "\n",
        "# モデルの定義\n",
        "model = MyRNN(VOCAB_SIZE, EMB_SIZE, HIDDEN_SIZE, num_layers, OUTPUT_SIZE, PADDING_IDX, bidirectional, device, emb_weights=weights)\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "max_epoch=1\n",
        "train_loss_log, train_acc_log = [], [] \n",
        "valid_loss_log, valid_acc_log = [], [] \n",
        "for epoch in range(max_epoch):\n",
        "    for batch in train_loader:\n",
        "        x, t = batch  # バッチサイズ分のサンプルを抽出\n",
        "        optimizer.zero_grad()   # 勾配を初期化\n",
        "\n",
        "        # 順伝播\n",
        "        y = model(x) \n",
        "        loss = criterion(y, t)\n",
        "        # 誤差逆伝播\n",
        "        loss.backward()\n",
        "        optimizer.step() \n",
        "\n",
        "    # 学習データの損失、正解率を確認\n",
        "    train_loss, train_acc = calculate_loss_and_accuracy(model, criterion, train_loader, device)\n",
        "    # 検証データの損失、正解率を確認\n",
        "    valid_loss, valid_acc = calculate_loss_and_accuracy(model, criterion, valid_loader, device)\n",
        "    print(\"epoch: %d    train_loss: %.3f   train_acc: %.3f   valid_loss: %.3f   valid_acc: %.3f\" % (epoch+1, train_loss, train_acc, valid_loss, valid_acc))\n",
        "\n",
        "    # 進捗状況の保存\n",
        "    train_loss_log.append(train_loss)\n",
        "    train_acc_log.append(train_acc)\n",
        "    valid_loss_log.append(valid_loss)\n",
        "    valid_acc_log.append(valid_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BexvpwELik_1",
        "outputId": "2218a8ea-5f85-4917-e919-837c06c18aa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "epoch: 1    train_loss: 0.912   train_acc: 0.667   valid_loss: 0.971   valid_acc: 0.635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "86"
      ],
      "metadata": {
        "id": "myO1CYxPpBsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import functional as F\n",
        "\n",
        "class MyCNN(nn.Module):\n",
        "  def __init__(self, vocab_size, emb_size, padding_idx, output_size, out_channels, kernel_heights, stride, padding, emb_weights=None):\n",
        "    super().__init__()\n",
        "    if emb_weights != None:  # 指定があれば埋め込み層の重みをemb_weightsで初期化\n",
        "      self.emb = nn.Embedding.from_pretrained(emb_weights, padding_idx=padding_idx)\n",
        "    else:\n",
        "      self.emb = nn.Embedding(vocab_size, emb_size, padding_idx=padding_idx)\n",
        "    self.conv = nn.Conv2d(1, out_channels, (kernel_heights, emb_size), stride, (padding, 0))\n",
        "    self.drop = nn.Dropout(0.3)\n",
        "    self.fc = nn.Linear(out_channels, output_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x.size() = (batch_size, seq_len)\n",
        "    emb = self.emb(x).unsqueeze(1)\n",
        "    # emb.size() = (batch_size, 1, seq_len, emb_size)\n",
        "    conv = self.conv(emb)\n",
        "    # conv.size() = (batch_size, out_channels, seq_len, 1)\n",
        "    act = F.relu(conv.squeeze(3))\n",
        "    # act.size() = (batch_size, out_channels, seq_len)\n",
        "    max_pool = F.max_pool1d(act, act.size()[2])\n",
        "    # max_pool.size() = (batch_size, out_channels, 1) -> seq_len方向に最大値を取得\n",
        "    out = self.fc(self.drop(max_pool.squeeze(2)))\n",
        "    # out.size() = (batch_size, output_size)\n",
        "    return out"
      ],
      "metadata": {
        "id": "1KUuSLCxpDkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# パラメータの設定\n",
        "VOCAB_SIZE = len(set(id_word_dic.values())) + 1\n",
        "EMB_SIZE = 300\n",
        "PADDING_IDX = len(set(id_word_dic.values()))\n",
        "OUTPUT_SIZE = 4\n",
        "OUT_CHANNELS = 100\n",
        "KERNEL_HEIGHTS = 3\n",
        "STRIDE = 1\n",
        "PADDING = 1\n",
        "\n",
        "# モデルの定義\n",
        "model = MyCNN(VOCAB_SIZE, EMB_SIZE, PADDING_IDX, OUTPUT_SIZE, OUT_CHANNELS, KERNEL_HEIGHTS, STRIDE, PADDING, emb_weights=weights)\n",
        "\n",
        "# 先頭10件の予測値取得\n",
        "for i in range(10):\n",
        "  X = dataset_train[i][0]\n",
        "  print(torch.softmax(model(X.unsqueeze(0)), dim=-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNlzvaPIpQd-",
        "outputId": "c3f6b608-0184-4798-f012-dc5c0ef1efd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2586, 0.2016, 0.2231, 0.3166]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2354, 0.2531, 0.2349, 0.2766]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2430, 0.2149, 0.2223, 0.3197]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.1922, 0.2413, 0.2252, 0.3413]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2166, 0.2546, 0.2294, 0.2994]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2274, 0.2574, 0.2024, 0.3127]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2391, 0.2813, 0.2025, 0.2771]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2571, 0.2559, 0.2241, 0.2629]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2494, 0.2862, 0.1735, 0.2909]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[0.2198, 0.2234, 0.2339, 0.3229]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "87"
      ],
      "metadata": {
        "id": "4Q-kNZGjqKVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# パラメータの設定\n",
        "VOCAB_SIZE = len(set(id_word_dic.values())) + 1\n",
        "EMB_SIZE = 300\n",
        "PADDING_IDX = len(set(id_word_dic.values()))\n",
        "OUTPUT_SIZE = 4\n",
        "OUT_CHANNELS = 100\n",
        "KERNEL_HEIGHTS = 3\n",
        "STRIDE = 1\n",
        "PADDING = 1\n",
        "\n",
        "# モデルの定義\n",
        "model = MyCNN(VOCAB_SIZE, EMB_SIZE, PADDING_IDX, OUTPUT_SIZE, OUT_CHANNELS, KERNEL_HEIGHTS, STRIDE, PADDING, emb_weights=weights)\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "max_epoch=1\n",
        "train_loss_log, train_acc_log = [], [] \n",
        "valid_loss_log, valid_acc_log = [], [] \n",
        "for epoch in range(max_epoch):\n",
        "    for batch in train_loader:\n",
        "        x, t = batch  # バッチサイズ分のサンプルを抽出\n",
        "        optimizer.zero_grad()   # 勾配を初期化\n",
        "\n",
        "        # 順伝播\n",
        "        y = model(x) \n",
        "        loss = criterion(y, t)\n",
        "        # 誤差逆伝播\n",
        "        loss.backward()\n",
        "        optimizer.step() \n",
        "\n",
        "    # 学習データの損失、正解率を確認\n",
        "    train_loss, train_acc = calculate_loss_and_accuracy(model, criterion, train_loader, device)\n",
        "    # 検証データの損失、正解率を確認\n",
        "    valid_loss, valid_acc = calculate_loss_and_accuracy(model, criterion, valid_loader, device)\n",
        "    print(\"epoch: %d    train_loss: %.3f   train_acc: %.3f   valid_loss: %.3f   valid_acc: %.3f\" % (epoch+1, train_loss, train_acc, valid_loss, valid_acc))\n",
        "\n",
        "    # 進捗状況の保存\n",
        "    train_loss_log.append(train_loss)\n",
        "    train_acc_log.append(train_acc)\n",
        "    valid_loss_log.append(valid_loss)\n",
        "    valid_acc_log.append(valid_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AmTcb86qLq4",
        "outputId": "cdd4e0ba-9eaa-4a97-e0ad-e48336c4bf5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "epoch: 1    train_loss: 0.740   train_acc: 0.725   valid_loss: 0.874   valid_acc: 0.678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "88"
      ],
      "metadata": {
        "id": "Wxuw8htJqzDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    # チューニング対象パラメータのセット\n",
        "    emb_size = int(trial.suggest_discrete_uniform('emb_size', 100, 400, 100))\n",
        "    out_channels = int(trial.suggest_discrete_uniform('out_channels', 50, 200, 50))\n",
        "    drop_rate = trial.suggest_discrete_uniform('drop_rate', 0.0, 0.5, 0.1)\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 5e-4, 5e-2)\n",
        "    momentum = trial.suggest_discrete_uniform('momentum', 0.5, 0.9, 0.1)\n",
        "    batch_size = int(trial.suggest_discrete_uniform('batch_size', 16, 128, 16))\n",
        "\n",
        "    # 固定パラメータの設定\n",
        "    VOCAB_SIZE = len(set(id_word_dic.values())) + 1\n",
        "    PADDING_IDX = len(set(id_word_dic.values()))\n",
        "    OUTPUT_SIZE = 4\n",
        "    CONV_PARAMS = [[2, 0], [3, 1], [4, 2]]\n",
        "    NUM_EPOCHS = 30\n",
        "\n",
        "    # モデルの定義\n",
        "    model = MyCNN(VOCAB_SIZE, EMB_SIZE, PADDING_IDX, OUTPUT_SIZE, OUT_CHANNELS, KERNEL_HEIGHTS, STRIDE, PADDING, emb_weights=weights)\n",
        "\n",
        "    # 損失関数の定義\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # オプティマイザの定義\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
        "\n",
        "    # デバイスの指定\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "    # モデルの学習\n",
        "    max_epoch=1\n",
        "    for epoch in range(max_epoch):\n",
        "        for batch in train_loader:\n",
        "            x, t = batch  # バッチサイズ分のサンプルを抽出\n",
        "            optimizer.zero_grad()   # 勾配を初期化\n",
        "\n",
        "            # 順伝播\n",
        "            y = model(x) \n",
        "            loss = criterion(y, t)\n",
        "            # 誤差逆伝播\n",
        "            loss.backward()\n",
        "            optimizer.step() \n",
        "\n",
        "        # 学習データの損失、正解率を確認\n",
        "        train_loss, train_acc = calculate_loss_and_accuracy(model, criterion, train_loader, device)\n",
        "        # 検証データの損失、正解率を確認\n",
        "        valid_loss, valid_acc = calculate_loss_and_accuracy(model, criterion, valid_loader, device)\n",
        "        print(\"epoch: %d    train_loss: %.3f   train_acc: %.3f   valid_loss: %.3f   valid_acc: %.3f\" % (epoch+1, train_loss, train_acc, valid_loss, valid_acc))\n",
        "\n",
        "        # 進捗状況の保存\n",
        "        train_loss_log.append(train_loss)\n",
        "        train_acc_log.append(train_acc)\n",
        "        valid_loss_log.append(valid_loss)\n",
        "        valid_acc_log.append(valid_acc)\n",
        "\n",
        "  # 損失の算出\n",
        "        valid_loss, valid_acc = calculate_loss_and_accuracy(model, criterion, valid_loader, device)\n",
        "    return valid_loss"
      ],
      "metadata": {
        "id": "24vgIbZonVCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltYah7TlonB9",
        "outputId": "112a7271-41b1-426a-a8b8-79763e5c5266"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-2.10.1-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.40)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.0)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.7 MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 38.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.12.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.9.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.1-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.6 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.10.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 57.2 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 60.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=23682d31ca71a9db587f9a10e7e84ee44eb290cd7d2d7ab4cd0ff9d72d340d63\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.1 alembic-1.8.1 autopage-0.5.1 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.2 colorlog-6.6.0 optuna-2.10.1 pbr-5.10.0 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "para=optuna.create_study()\n",
        "para.optimize(objective, n_trials=5)\n",
        "best = para.best_trial\n",
        "print(best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "jnF3NZUloj1l",
        "outputId": "6f3c0ce4-3b71-46f5-cd20-0e526e3b0a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-08-24 16:22:48,458]\u001b[0m A new study created in memory with name: no-name-01dbe0ab-a1e5-4604-a023-cfae74621ec3\u001b[0m\n",
            "\u001b[33m[W 2022-08-24 16:23:05,772]\u001b[0m Trial 0 failed because of the following error: RuntimeError('No CUDA GPUs are available')\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-30-64025ec19850>\", line 44, in objective\n",
            "    train_loss, train_acc = calculate_loss_and_accuracy(model, criterion, train_loader, device)\n",
            "  File \"<ipython-input-32-74265d89aad4>\", line 9, in calculate_loss_and_accuracy\n",
            "    x = x.to(device)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\", line 217, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: No CUDA GPUs are available\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-e86afc9de33e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpara\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpara\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpara\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-64025ec19850>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# 学習データの損失、正解率を確認\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_loss_and_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;31m# 検証データの損失、正解率を確認\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_loss_and_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-74265d89aad4>\u001b[0m in \u001b[0;36mcalculate_loss_and_accuracy\u001b[0;34m(model, criterion, dataloader, device)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# デバイスの指定\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "89"
      ],
      "metadata": {
        "id": "hYAMSFl2x86v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================\n",
        "# ライブラリのインストール\n",
        "# ====================\n",
        "\n",
        "! pip install transformers==4.5.0\n",
        "! pip install fugashi==1.1.0\n",
        "! pip install ipadic==1.0.0\n",
        "! pip install pytorch-lightning==1.2.7\n",
        "\n",
        "import glob\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertJapaneseTokenizer\n",
        "from transformers import BertForSequenceClassification"
      ],
      "metadata": {
        "id": "moobr7urqVko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================\n",
        "# 前処理：データ形式の整理\n",
        "# ====================\n",
        "\n",
        "label2id = {\"b\":0, \"t\":1, \"e\":2, \"m\":3} \n",
        "\n",
        "model_name = \"cl-tohoku/bert-base-japanese-whole-word-masking\"\n",
        "\n",
        "# 単語分割器の読み込み\n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# 最大文長さの設定\n",
        "max_length = 128\n",
        "\n",
        "def make_dataset(tokenizer, max_length, fname):\n",
        "    dataset_for_loader = list()\n",
        "    \n",
        "    fin = open(fname, \"r\")\n",
        "    for line in fin:\n",
        "        # ラベルとテキストを読み込み\n",
        "        label, text = line.strip().split(\"\\t\")\n",
        "\n",
        "        # テキストをトークンに分割する。ただし、最大文長は \"max_length\" で指定したトークン数である。\n",
        "        # 最大文長より短い文については、 \"[PAD]\" などの特殊トークンで残りの長さを埋める。\n",
        "        # 最大文長を超える文については、はみ出す部分を無視する。\n",
        "        encoding = tokenizer(text, max_length=max_length, padding=\"max_length\", truncation=True)\n",
        "\n",
        "        # tokenizerメソッドは辞書を返す。その辞書にラベルのIDも持たせる。\n",
        "        encoding[\"labels\"] = label2id[label]\n",
        "\n",
        "        # テンソルに変換\n",
        "        encoding = {key: torch.tensor(value) for key, value in encoding.items()}\n",
        "\n",
        "        # 前処理済みのデータを保存して次の文へ\n",
        "        dataset_for_loader.append(encoding)\n",
        "    fin.close()\n",
        "\n",
        "    return dataset_for_loader\n",
        "\n",
        "dataset_train = make_dataset(tokenizer, max_length, fname_train)\n",
        "dataset_val = make_dataset(tokenizer, max_length, fname_val)\n",
        "dataset_test = make_dataset(tokenizer, max_length, fname_test)\n",
        "\n",
        "# データローダを作成。訓練用データはシャッフルしながら使う。\n",
        "# 検証用と評価用は損失の勾配を計算する必要がないため、バッチサイズを大きめにとれる。\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
        "dataloader_val = DataLoader(dataset_val, batch_size=256, shuffle=False)\n",
        "dataloader_test = DataLoader(dataset_test, batch_size=256, shuffle=False)"
      ],
      "metadata": {
        "id": "yFz4iyI5x9t_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================\n",
        "# BERTによるテキスト分類\n",
        "# ====================\n",
        "\n",
        "class Bert4Classification(pl.LightningModule):\n",
        "\n",
        "    # モデルの読み込みなど。損失関数は自動的に設定される。\n",
        "    # num_labels == 1 -> 回帰タスクなので MSELoss()\n",
        "    # num_labels > 1 -> 分類タスクなので CrossEntropyLoss()\n",
        "    def __init__(self, model_name, num_labels, lr):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()    # num_labelsとlrを保存する。例えば、self.hparams.lrでlrにアクセスできる。\n",
        "        self.bert_sc = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
        "\n",
        "    # 訓練用データのバッチを受け取って損失を計算\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        output = self.bert_sc(**batch)\n",
        "        loss = output.loss\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    # 検証用データのバッチを受け取って損失を計算\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        output = self.bert_sc(**batch)\n",
        "        val_loss = output.loss\n",
        "        self.log(\"val_loss\", val_loss)\n",
        "\n",
        "    # 評価用データのバッチを受け取って分類の正解率を計算\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        # ラベルの推定\n",
        "        output = self.bert_sc(**batch)\n",
        "        labels_predicted = output.logits.argmax(-1)\n",
        "        # 正解率の計算\n",
        "        labels = batch.pop(\"labels\")\n",
        "        num_correct = (labels_predicted == labels).sum().item()\n",
        "        accuracy = num_correct / labels.size(0)\n",
        "        self.log(\"accuracy\", accuracy)\n",
        "\n",
        "    # 最適化手法を設定\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)"
      ],
      "metadata": {
        "id": "7h2KnXCrqQAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================\n",
        "# 訓練\n",
        "# ====================\n",
        "\n",
        "model = Bert4Classification(model_name, num_labels=len(label2id), lr=1e-5)\n",
        "\n",
        "# 訓練中にモデルを保存するための設定\n",
        "checkpoint = pl.callbacks.ModelCheckpoint(\n",
        "    # 検証用データにおける損失が最も小さいモデルを保存する\n",
        "    monitor=\"val_loss\", mode=\"min\", save_top_k=1,\n",
        "    # モデルファイル（重みのみ）を \"model\" というディレクトリに保存する\n",
        "    save_weights_only=True, dirpath=\"model/\"\n",
        ")\n",
        "\n",
        "# 訓練\n",
        "trainer = pl.Trainer(gpus=1, max_epochs=3, callbacks=[checkpoint])\n",
        "trainer.fit(model, dataloader_train, dataloader_val)\n",
        "\n",
        "# ベストモデルの確認\n",
        "print(\"ベストモデル: \", checkpoint.best_model_path)\n",
        "print(\"ベストモデルの検証用データにおける損失: \", checkpoint.best_model_score)"
      ],
      "metadata": {
        "id": "RShq3c7hqRp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================\n",
        "# 評価\n",
        "# ====================\n",
        "\n",
        "test = trainer.test(test_dataloaders=dataloader_test)\n",
        "print(\"Test accuracy = %.3f\" % (test[0][\"accuracy\"]))"
      ],
      "metadata": {
        "id": "CLPD7EClqTBb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}